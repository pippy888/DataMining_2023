2024-01-01 02:35:05,610 - INFO - Log directory: ./libcity/log
2024-01-01 02:35:05,611 - INFO - Begin pretrain-pipeline, task=trajectory_embedding, model_name=BERTContrastiveLM, dataset_name=bj, exp_id=247850
2024-01-01 02:35:05,611 - INFO - {'task': 'trajectory_embedding', 'model': 'BERTContrastiveLM', 'dataset': 'bj', 'saved_model': True, 'train': True, 'gpu': True, 'gpu_id': 0, 'distribution': 'geometric', 'avg_mask_len': 2, 'contra_ratio': 0.4, 'mlm_ratio': 0.6, 'split': True, 'n_layers': 6, 'd_model': 256, 'attn_heads': 8, 'max_epoch': 30, 'batch_size': 8, 'grad_accmu_steps': 1, 'learning_rate': 0.0002, 'roadnetwork': 'bj_roadmap_edge_bj_True_1_merge', 'geo_file': 'bj_roadmap_edge_bj_True_1_merge_withdegree', 'rel_file': 'bj_roadmap_edge_bj_True_1_merge_withdegree', 'merge': True, 'min_freq': 1, 'seq_len': 128, 'test_every': 50, 'temperature': 0.05, 'contra_loss_type': 'simclr', 'classify_label': 'vflag', 'type_ln': 'post', 'add_cls': True, 'add_time_in_day': True, 'add_day_in_week': True, 'add_pe': True, 'add_temporal_bias': True, 'temporal_bias_dim': 64, 'use_mins_interval': False, 'add_gat': True, 'gat_heads_per_layer': [8, 16, 1], 'gat_features_per_layer': [16, 16, 256], 'gat_dropout': 0.1, 'gat_K': 1, 'gat_avg_last': True, 'load_trans_prob': True, 'append_degree2gcn': True, 'normal_feature': False, 'pooling': 'cls', 'dataset_class': 'ContrastiveSplitLMDataset', 'executor': 'ContrastiveSplitMLMExecutor', 'evaluator': 'ClassificationEvaluator', 'num_workers': 0, 'vocab_path': None, 'masking_ratio': 0.15, 'masking_mode': 'together', 'mlp_ratio': 4, 'pretrain_road_emb': None, 'future_mask': False, 'load_node2vec': False, 'dropout': 0.1, 'drop_path': 0.3, 'attn_drop': 0.1, 'seed': 0, 'learner': 'adamw', 'lr_eta_min': 0, 'lr_warmup_epoch': 4, 'lr_warmup_init': 1e-06, 'lr_decay': True, 'lr_scheduler': 'cosinelr', 'lr_decay_ratio': 0.1, 't_in_epochs': True, 'clip_grad_norm': True, 'max_grad_norm': 5, 'use_early_stop': True, 'patience': 10, 'log_batch': 500, 'log_every': 1, 'l2_reg': None, 'n_views': 2, 'similarity': 'cosine', 'data_argument1': [], 'data_argument2': [], 'cutoff_row_rate': 0.2, 'cutoff_column_rate': 0.2, 'cutoff_random_rate': 0.2, 'sample_rate': 0.2, 'align_w': 1.0, 'unif_w': 1.0, 'align_alpha': 2, 'unif_t': 2, 'train_align_uniform': False, 'test_align_uniform': True, 'norm_align_uniform': False, 'bidir_adj_mx': False, 'out_data_argument1': None, 'out_data_argument2': None, 'metrics': ['Precision', 'Recall', 'F1', 'MRR', 'NDCG'], 'save_modes': ['csv', 'json'], 'topk': [1, 5, 10], 'device': device(type='cuda', index=0), 'exp_id': 247850}
2024-01-01 02:35:06,186 - INFO - Loading Vocab from raw_data/vocab_bj_True_1_merge.pkl
2024-01-01 02:35:06,193 - INFO - vocab_path=raw_data/vocab_bj_True_1_merge.pkl, usr_num=75, vocab_size=27313
2024-01-01 02:35:06,251 - INFO - Loaded file bj_roadmap_edge_bj_True_1_merge_withdegree.geo, num_nodes=27309
2024-01-01 02:35:07,764 - INFO - Loaded file bj_roadmap_edge_bj_True_1_merge_withdegree.rel, shape=(27309, 27309), edges=51196.0
2024-01-01 02:35:07,774 - INFO - node_features: (27309, 42)
2024-01-01 02:35:09,719 - INFO - node_features_encoded: torch.Size([27313, 42])
2024-01-01 02:35:09,865 - INFO - edge_index: torch.Size([2, 78471])
2024-01-01 02:35:09,871 - INFO - Trajectory loc-transfer prob shape=torch.Size([78471, 1])
2024-01-01 02:35:09,880 - INFO - Loading Dataset!
2024-01-01 02:35:10,853 - INFO - Load dataset from raw_data/bj/cache_bj_train_True_True_1.pkl
2024-01-01 02:35:10,853 - INFO - Init TrajectoryProcessingDatasetSplitLM!
2024-01-01 02:35:12,384 - INFO - Load dataset from raw_data/bj/cache_bj_train_True_True_1.pkl, raw_data/bj/cache_bj_train_True_True_1.pkl
2024-01-01 02:35:12,751 - INFO - Load dataset from raw_data/bj/cache_bj_eval_True_True_1.pkl
2024-01-01 02:35:12,752 - INFO - Init TrajectoryProcessingDatasetSplitLM!
2024-01-01 02:35:13,265 - INFO - Load dataset from raw_data/bj/cache_bj_eval_True_True_1.pkl, raw_data/bj/cache_bj_eval_True_True_1.pkl
2024-01-01 02:35:13,600 - INFO - Load dataset from raw_data/bj/cache_bj_test_True_True_1.pkl
2024-01-01 02:35:13,601 - INFO - Init TrajectoryProcessingDatasetSplitLM!
2024-01-01 02:35:14,136 - INFO - Load dataset from raw_data/bj/cache_bj_test_True_True_1.pkl, raw_data/bj/cache_bj_test_True_True_1.pkl
2024-01-01 02:35:14,136 - INFO - Size of dataset: 10510/3504/3504
2024-01-01 02:35:14,136 - INFO - Creating Dataloader!
2024-01-01 02:35:14,139 - INFO - Building BERTContrastiveLM model
2024-01-01 02:35:14,226 - INFO - Building BERTPooler model
2024-01-01 02:35:15,063 - INFO - BERTContrastiveLM(
  (bert): BERT(
    (embedding): BERTEmbedding(
      (token_embedding): GAT(
        (gat_net): Sequential(
          (0): GATLayerImp3(
            (linear_proj): Linear(in_features=42, out_features=128, bias=False)
            (linear_proj_tran_prob): Linear(in_features=1, out_features=128, bias=False)
            (skip_proj): Linear(in_features=42, out_features=128, bias=False)
            (leakyReLU): LeakyReLU(negative_slope=0.2)
            (softmax): Softmax(dim=-1)
            (activation): ELU(alpha=1.0)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (1): GATLayerImp3(
            (linear_proj): Linear(in_features=128, out_features=256, bias=False)
            (linear_proj_tran_prob): Linear(in_features=1, out_features=256, bias=False)
            (skip_proj): Linear(in_features=128, out_features=256, bias=False)
            (leakyReLU): LeakyReLU(negative_slope=0.2)
            (softmax): Softmax(dim=-1)
            (activation): ELU(alpha=1.0)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (2): GATLayerImp3(
            (linear_proj): Linear(in_features=256, out_features=256, bias=False)
            (linear_proj_tran_prob): Linear(in_features=1, out_features=256, bias=False)
            (skip_proj): Linear(in_features=256, out_features=256, bias=False)
            (leakyReLU): LeakyReLU(negative_slope=0.2)
            (softmax): Softmax(dim=-1)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (position_embedding): PositionalEmbedding()
      (daytime_embedding): Embedding(1441, 256, padding_idx=0)
      (weekday_embedding): Embedding(8, 256, padding_idx=0)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (transformer_blocks): ModuleList(
      (0): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath()
      )
      (2): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath()
      )
      (3): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath()
      )
      (4): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath()
      )
      (5): TransformerBlock(
        (attention): MultiHeadedAttention(
          (linear_layers): ModuleList(
            (0): Linear(in_features=256, out_features=256, bias=True)
            (1): Linear(in_features=256, out_features=256, bias=True)
            (2): Linear(in_features=256, out_features=256, bias=True)
          )
          (dropout): Dropout(p=0.1, inplace=False)
          (proj): Linear(in_features=256, out_features=256, bias=True)
          (proj_drop): Dropout(p=0.1, inplace=False)
          (temporal_mat_bias_1): Linear(in_features=1, out_features=64, bias=True)
          (temporal_mat_bias_2): Linear(in_features=64, out_features=1, bias=True)
        )
        (mlp): Mlp(
          (fc1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU()
          (fc2): Linear(in_features=1024, out_features=256, bias=True)
          (drop): Dropout(p=0.1, inplace=False)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (drop_path): DropPath()
      )
    )
  )
  (mask_l): MaskedLanguageModel(
    (linear): Linear(in_features=256, out_features=27313, bias=True)
    (softmax): LogSoftmax(dim=-1)
  )
  (pooler): BERTPooler(
    (linear): MLPLayer(
      (dense): Linear(in_features=256, out_features=256, bias=True)
      (activation): Tanh()
    )
  )
)
2024-01-01 02:35:15,066 - INFO - bert.embedding.token_embedding.gat_net.0.scoring_fn_target	torch.Size([1, 8, 16])	cuda:0	True
2024-01-01 02:35:15,066 - INFO - bert.embedding.token_embedding.gat_net.0.scoring_fn_source	torch.Size([1, 8, 16])	cuda:0	True
2024-01-01 02:35:15,066 - INFO - bert.embedding.token_embedding.gat_net.0.scoring_trans_prob	torch.Size([1, 8, 16])	cuda:0	True
2024-01-01 02:35:15,066 - INFO - bert.embedding.token_embedding.gat_net.0.bias	torch.Size([128])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.0.linear_proj.weight	torch.Size([128, 42])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.0.linear_proj_tran_prob.weight	torch.Size([128, 1])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.0.skip_proj.weight	torch.Size([128, 42])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.1.scoring_fn_target	torch.Size([1, 16, 16])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.1.scoring_fn_source	torch.Size([1, 16, 16])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.1.scoring_trans_prob	torch.Size([1, 16, 16])	cuda:0	True
2024-01-01 02:35:15,067 - INFO - bert.embedding.token_embedding.gat_net.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.1.linear_proj.weight	torch.Size([256, 128])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.1.linear_proj_tran_prob.weight	torch.Size([256, 1])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.1.skip_proj.weight	torch.Size([256, 128])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.2.scoring_fn_target	torch.Size([1, 1, 256])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.2.scoring_fn_source	torch.Size([1, 1, 256])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.2.scoring_trans_prob	torch.Size([1, 1, 256])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,068 - INFO - bert.embedding.token_embedding.gat_net.2.linear_proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.embedding.token_embedding.gat_net.2.linear_proj_tran_prob.weight	torch.Size([256, 1])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.embedding.token_embedding.gat_net.2.skip_proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.embedding.daytime_embedding.weight	torch.Size([1441, 256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.embedding.weekday_embedding.weight	torch.Size([8, 256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.transformer_blocks.0.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.transformer_blocks.0.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,069 - INFO - bert.transformer_blocks.0.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,070 - INFO - bert.transformer_blocks.0.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,071 - INFO - bert.transformer_blocks.0.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,072 - INFO - bert.transformer_blocks.1.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,073 - INFO - bert.transformer_blocks.1.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.1.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.1.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.1.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.1.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.2.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.2.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.2.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,074 - INFO - bert.transformer_blocks.2.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,075 - INFO - bert.transformer_blocks.2.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.2.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,076 - INFO - bert.transformer_blocks.3.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,077 - INFO - bert.transformer_blocks.3.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,078 - INFO - bert.transformer_blocks.3.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.3.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.3.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,079 - INFO - bert.transformer_blocks.4.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,080 - INFO - bert.transformer_blocks.4.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.4.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.4.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.4.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.4.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.4.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.5.attention.linear_layers.0.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.5.attention.linear_layers.0.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.5.attention.linear_layers.1.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,081 - INFO - bert.transformer_blocks.5.attention.linear_layers.1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.linear_layers.2.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.linear_layers.2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.proj.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.proj.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.temporal_mat_bias_1.weight	torch.Size([64, 1])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.temporal_mat_bias_1.bias	torch.Size([64])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.temporal_mat_bias_2.weight	torch.Size([1, 64])	cuda:0	True
2024-01-01 02:35:15,082 - INFO - bert.transformer_blocks.5.attention.temporal_mat_bias_2.bias	torch.Size([1])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.mlp.fc1.weight	torch.Size([1024, 256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.mlp.fc1.bias	torch.Size([1024])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.mlp.fc2.weight	torch.Size([256, 1024])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.mlp.fc2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.norm1.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.norm1.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.norm2.weight	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - bert.transformer_blocks.5.norm2.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,083 - INFO - mask_l.linear.weight	torch.Size([27313, 256])	cuda:0	True
2024-01-01 02:35:15,084 - INFO - mask_l.linear.bias	torch.Size([27313])	cuda:0	True
2024-01-01 02:35:15,084 - INFO - pooler.linear.dense.weight	torch.Size([256, 256])	cuda:0	True
2024-01-01 02:35:15,084 - INFO - pooler.linear.dense.bias	torch.Size([256])	cuda:0	True
2024-01-01 02:35:15,085 - INFO - Total parameter numbers: 12406455
2024-01-01 02:35:15,085 - INFO - You select `adamw` optimizer.
2024-01-01 02:35:15,086 - INFO - You select `cosinelr` lr_scheduler.
2024-01-01 02:35:15,091 - INFO - Start training ...
2024-01-01 02:35:15,092 - INFO - Num_batches: train=1314, eval=438
2024-01-01 02:35:16,792 - INFO - {'mode': 'Train', 'epoch': 0, 'iter': 0, 'lr': 1e-06, 'Loc acc(%)': 0.0, 'MLM loss': 10.395675659179688, 'Contrastive loss': 0.13149219751358032, 'align_loss': 32.58811950683594, 'uniform_loss': -inf}
2024-01-01 02:37:30,428 - INFO - {'mode': 'Train', 'epoch': 0, 'iter': 500, 'lr': 1e-06, 'Loc acc(%)': 0.0043496226702333576, 'MLM loss': 10.336137771606445, 'Contrastive loss': 0.059704165905714035, 'align_loss': 36.77821350097656, 'uniform_loss': -inf}
2024-01-01 02:39:45,295 - INFO - {'mode': 'Train', 'epoch': 0, 'iter': 1000, 'lr': 1e-06, 'Loc acc(%)': 0.005493237824238362, 'MLM loss': 10.365951538085938, 'Contrastive loss': 0.01294209435582161, 'align_loss': 32.354942321777344, 'uniform_loss': -inf}
2024-01-01 02:41:10,494 - INFO - Train: expid = 247850, Epoch = 0, avg_loss = 6.259453099249342, total_loc_acc = 0.005858721124874456%.
2024-01-01 02:41:10,494 - INFO - epoch complete!
2024-01-01 02:41:10,494 - INFO - evaluating now!
2024-01-01 02:41:10,594 - INFO - {'mode': 'Train', 'epoch': 0, 'iter': 0, 'lr': 1e-06, 'Loc acc(%)': 0.0, 'MLM loss': 10.440339088439941, 'Contrastive loss': 0.00031270552426576614, 'align_loss': 1.9708963350240083e-07, 'uniform_loss': -82.77632141113281}
2024-01-01 02:41:51,083 - INFO - Eval: expid = 247850, Epoch = 0, avg_loss = 6.205565890220747, total_loc_acc = 0.005025251890751024%.
2024-01-01 02:41:51,083 - INFO - Epoch [0/30] (1314)  train_loss: 6.2595, val_loss: 6.2056, lr: 0.000051, 395.99s
2024-01-01 02:41:51,433 - INFO - Saved model at 0
2024-01-01 02:41:51,433 - INFO - Val loss decrease from inf to 6.2056, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch0.tar
2024-01-01 02:41:51,703 - INFO - {'mode': 'Train', 'epoch': 1, 'iter': 0, 'lr': 5.075e-05, 'Loc acc(%)': 0.0, 'MLM loss': 10.410309791564941, 'Contrastive loss': 0.05396502465009689, 'align_loss': 35.39919662475586, 'uniform_loss': -inf}
2024-01-01 02:44:08,104 - INFO - {'mode': 'Train', 'epoch': 1, 'iter': 500, 'lr': 5.075e-05, 'Loc acc(%)': 0.02166002425922717, 'MLM loss': 9.697013854980469, 'Contrastive loss': 0.0008424187544733286, 'align_loss': 20.11129379272461, 'uniform_loss': -68.32022857666016}
2024-01-01 02:46:24,771 - INFO - {'mode': 'Train', 'epoch': 1, 'iter': 1000, 'lr': 5.075e-05, 'Loc acc(%)': 0.03597828220056257, 'MLM loss': 9.32019329071045, 'Contrastive loss': 0.011776802130043507, 'align_loss': 21.609573364257812, 'uniform_loss': -63.92041778564453}
2024-01-01 02:47:50,418 - INFO - Train: expid = 247850, Epoch = 1, avg_loss = 5.8451525188835065, total_loc_acc = 0.042366897330885465%.
2024-01-01 02:47:50,418 - INFO - epoch complete!
2024-01-01 02:47:50,418 - INFO - evaluating now!
2024-01-01 02:47:50,508 - INFO - {'mode': 'Train', 'epoch': 1, 'iter': 0, 'lr': 5.075e-05, 'Loc acc(%)': 0.0, 'MLM loss': 9.06307601928711, 'Contrastive loss': 6.779958766855998e-06, 'align_loss': 2.1683436557395908e-07, 'uniform_loss': -95.80472564697266}
2024-01-01 02:48:31,148 - INFO - Eval: expid = 247850, Epoch = 1, avg_loss = 5.723852196784868, total_loc_acc = 0.051034729133175125%.
2024-01-01 02:48:31,158 - INFO - Epoch [1/30] (2628)  train_loss: 5.8452, val_loss: 5.7239, lr: 0.000101, 399.72s
2024-01-01 02:48:31,518 - INFO - Saved model at 1
2024-01-01 02:48:31,518 - INFO - Val loss decrease from 6.2056 to 5.7239, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch1.tar
2024-01-01 02:48:31,788 - INFO - {'mode': 'Train', 'epoch': 2, 'iter': 0, 'lr': 0.0001005, 'Loc acc(%)': 0.0, 'MLM loss': 9.531121253967285, 'Contrastive loss': 0.013159464113414288, 'align_loss': 24.530330657958984, 'uniform_loss': -inf}
2024-01-01 02:50:48,661 - INFO - {'mode': 'Train', 'epoch': 2, 'iter': 500, 'lr': 0.0001005, 'Loc acc(%)': 0.04918619209443749, 'MLM loss': 9.728178977966309, 'Contrastive loss': 0.017718469724059105, 'align_loss': 29.76082992553711, 'uniform_loss': -inf}
2024-01-01 02:53:05,294 - INFO - {'mode': 'Train', 'epoch': 2, 'iter': 1000, 'lr': 0.0001005, 'Loc acc(%)': 0.046414481318171275, 'MLM loss': 9.313101768493652, 'Contrastive loss': 0.0090686259791255, 'align_loss': 23.39514923095703, 'uniform_loss': -inf}
2024-01-01 02:54:31,004 - INFO - Train: expid = 247850, Epoch = 2, avg_loss = 5.710968974518449, total_loc_acc = 0.04695426151846728%.
2024-01-01 02:54:31,004 - INFO - epoch complete!
2024-01-01 02:54:31,004 - INFO - evaluating now!
2024-01-01 02:54:31,104 - INFO - {'mode': 'Train', 'epoch': 2, 'iter': 0, 'lr': 0.0001005, 'Loc acc(%)': 0.0, 'MLM loss': 9.30648136138916, 'Contrastive loss': 6.695704360026866e-05, 'align_loss': 3.037099531866261e-07, 'uniform_loss': -inf}
2024-01-01 02:55:11,901 - INFO - Eval: expid = 247850, Epoch = 2, avg_loss = 5.7155895864582495, total_loc_acc = 0.042907622412922765%.
2024-01-01 02:55:11,911 - INFO - Epoch [2/30] (3942)  train_loss: 5.7110, val_loss: 5.7156, lr: 0.000150, 400.39s
2024-01-01 02:55:12,251 - INFO - Saved model at 2
2024-01-01 02:55:12,251 - INFO - Val loss decrease from 5.7239 to 5.7156, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch2.tar
2024-01-01 02:55:12,521 - INFO - {'mode': 'Train', 'epoch': 3, 'iter': 0, 'lr': 0.00015025000000000002, 'Loc acc(%)': 0.0, 'MLM loss': 9.613308906555176, 'Contrastive loss': 0.0004692759539466351, 'align_loss': 18.95644760131836, 'uniform_loss': -inf}
2024-01-01 02:57:29,283 - INFO - {'mode': 'Train', 'epoch': 3, 'iter': 500, 'lr': 0.00015025000000000002, 'Loc acc(%)': 0.08349996703948669, 'MLM loss': 9.334832191467285, 'Contrastive loss': 0.00018031503714155406, 'align_loss': 21.551599502563477, 'uniform_loss': -inf}
2024-01-01 02:59:45,822 - INFO - {'mode': 'Train', 'epoch': 3, 'iter': 1000, 'lr': 0.00015025000000000002, 'Loc acc(%)': 0.08153551202097886, 'MLM loss': 9.118191719055176, 'Contrastive loss': 0.003497910685837269, 'align_loss': 20.32333755493164, 'uniform_loss': -inf}
2024-01-01 03:01:11,469 - INFO - Train: expid = 247850, Epoch = 3, avg_loss = 5.69035877738732, total_loc_acc = 0.0903433045573178%.
2024-01-01 03:01:11,469 - INFO - epoch complete!
2024-01-01 03:01:11,469 - INFO - evaluating now!
2024-01-01 03:01:11,569 - INFO - {'mode': 'Train', 'epoch': 3, 'iter': 0, 'lr': 0.00015025000000000002, 'Loc acc(%)': 0.0, 'MLM loss': 9.079171180725098, 'Contrastive loss': 0.028641875833272934, 'align_loss': 1.5166763489560253e-07, 'uniform_loss': -24.043743133544922}
2024-01-01 03:01:52,259 - INFO - Eval: expid = 247850, Epoch = 3, avg_loss = 5.652391740720566, total_loc_acc = 0.13282926330847042%.
2024-01-01 03:01:52,259 - INFO - Epoch [3/30] (5256)  train_loss: 5.6904, val_loss: 5.6524, lr: 0.000191, 400.01s
2024-01-01 03:01:52,689 - INFO - Saved model at 3
2024-01-01 03:01:52,689 - INFO - Val loss decrease from 5.7156 to 5.6524, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch3.tar
2024-01-01 03:01:52,959 - INFO - {'mode': 'Train', 'epoch': 4, 'iter': 0, 'lr': 0.0001913545457642601, 'Loc acc(%)': 0.0, 'MLM loss': 9.302064895629883, 'Contrastive loss': 0.0010411004768684506, 'align_loss': 20.300012588500977, 'uniform_loss': -inf}
2024-01-01 03:04:09,666 - INFO - {'mode': 'Train', 'epoch': 4, 'iter': 500, 'lr': 0.0001913545457642601, 'Loc acc(%)': 0.18132960478884932, 'MLM loss': 8.829893112182617, 'Contrastive loss': 0.0019349713111296296, 'align_loss': 15.648565292358398, 'uniform_loss': -inf}
2024-01-01 03:06:26,325 - INFO - {'mode': 'Train', 'epoch': 4, 'iter': 1000, 'lr': 0.0001913545457642601, 'Loc acc(%)': 0.18001009812745591, 'MLM loss': 8.876644134521484, 'Contrastive loss': 0.0625731572508812, 'align_loss': 15.690428733825684, 'uniform_loss': -69.30624389648438}
2024-01-01 03:07:51,842 - INFO - Train: expid = 247850, Epoch = 4, avg_loss = 5.543889431104268, total_loc_acc = 0.18991048272400235%.
2024-01-01 03:07:51,842 - INFO - epoch complete!
2024-01-01 03:07:51,842 - INFO - evaluating now!
2024-01-01 03:07:51,932 - INFO - {'mode': 'Train', 'epoch': 4, 'iter': 0, 'lr': 0.0001913545457642601, 'Loc acc(%)': 1.2987012987012987, 'MLM loss': 8.385466575622559, 'Contrastive loss': 0.0002418148797005415, 'align_loss': 1.1489028395317291e-07, 'uniform_loss': -83.63455200195312}
2024-01-01 03:08:32,542 - INFO - Eval: expid = 247850, Epoch = 4, avg_loss = 5.400015681845956, total_loc_acc = 0.31383155155257314%.
2024-01-01 03:08:32,542 - INFO - Epoch [4/30] (6570)  train_loss: 5.5439, val_loss: 5.4000, lr: 0.000187, 399.85s
2024-01-01 03:08:32,892 - INFO - Saved model at 4
2024-01-01 03:08:32,902 - INFO - Val loss decrease from 5.6524 to 5.4000, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch4.tar
2024-01-01 03:08:33,172 - INFO - {'mode': 'Train', 'epoch': 5, 'iter': 0, 'lr': 0.00018660254037844388, 'Loc acc(%)': 0.78125, 'MLM loss': 9.608440399169922, 'Contrastive loss': 0.0004614451318047941, 'align_loss': 17.11996078491211, 'uniform_loss': -inf}
2024-01-01 03:10:49,988 - INFO - {'mode': 'Train', 'epoch': 5, 'iter': 500, 'lr': 0.00018660254037844388, 'Loc acc(%)': 0.2818355887351821, 'MLM loss': 8.02957820892334, 'Contrastive loss': 0.007213016040623188, 'align_loss': 15.437002182006836, 'uniform_loss': -71.36553192138672}
2024-01-01 03:13:06,530 - INFO - {'mode': 'Train', 'epoch': 5, 'iter': 1000, 'lr': 0.00018660254037844388, 'Loc acc(%)': 0.33126249022504123, 'MLM loss': 8.019775390625, 'Contrastive loss': 0.000397129770135507, 'align_loss': 18.1581974029541, 'uniform_loss': -inf}
2024-01-01 03:14:32,128 - INFO - Train: expid = 247850, Epoch = 5, avg_loss = 5.261396639967618, total_loc_acc = 0.34994098382458066%.
2024-01-01 03:14:32,128 - INFO - epoch complete!
2024-01-01 03:14:32,128 - INFO - evaluating now!
2024-01-01 03:14:32,228 - INFO - {'mode': 'Train', 'epoch': 5, 'iter': 0, 'lr': 0.00018660254037844388, 'Loc acc(%)': 0.0, 'MLM loss': 8.615086555480957, 'Contrastive loss': 2.7566286007640883e-05, 'align_loss': 2.5932911285053706e-07, 'uniform_loss': -inf}
2024-01-01 03:15:12,850 - INFO - Eval: expid = 247850, Epoch = 5, avg_loss = 5.1145395710043715, total_loc_acc = 0.5367673000352804%.
2024-01-01 03:15:12,850 - INFO - Epoch [5/30] (7884)  train_loss: 5.2614, val_loss: 5.1145, lr: 0.000181, 399.95s
2024-01-01 03:15:13,210 - INFO - Saved model at 5
2024-01-01 03:15:13,210 - INFO - Val loss decrease from 5.4000 to 5.1145, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch5.tar
2024-01-01 03:15:13,480 - INFO - {'mode': 'Train', 'epoch': 6, 'iter': 0, 'lr': 0.00018090169943749476, 'Loc acc(%)': 0.0, 'MLM loss': 8.908769607543945, 'Contrastive loss': 0.0006820328999310732, 'align_loss': 20.983165740966797, 'uniform_loss': -inf}
2024-01-01 03:17:30,267 - INFO - {'mode': 'Train', 'epoch': 6, 'iter': 500, 'lr': 0.00018090169943749476, 'Loc acc(%)': 0.5391365084908544, 'MLM loss': 8.28499698638916, 'Contrastive loss': 0.004379250109195709, 'align_loss': 17.96102523803711, 'uniform_loss': -inf}
2024-01-01 03:19:46,910 - INFO - {'mode': 'Train', 'epoch': 6, 'iter': 1000, 'lr': 0.00018090169943749476, 'Loc acc(%)': 0.5852111135418945, 'MLM loss': 7.901426315307617, 'Contrastive loss': 0.0011240668827667832, 'align_loss': 20.14803695678711, 'uniform_loss': -inf}
2024-01-01 03:21:12,518 - INFO - Train: expid = 247850, Epoch = 6, avg_loss = 4.993507792416229, total_loc_acc = 0.6247862463609746%.
2024-01-01 03:21:12,518 - INFO - epoch complete!
2024-01-01 03:21:12,518 - INFO - evaluating now!
2024-01-01 03:21:12,608 - INFO - {'mode': 'Train', 'epoch': 6, 'iter': 0, 'lr': 0.00018090169943749476, 'Loc acc(%)': 0.0, 'MLM loss': 9.166597366333008, 'Contrastive loss': 0.015759071335196495, 'align_loss': 2.275625377023971e-07, 'uniform_loss': -72.56814575195312}
2024-01-01 03:21:53,218 - INFO - Eval: expid = 247850, Epoch = 6, avg_loss = 4.827562597244298, total_loc_acc = 1.1094137386992562%.
2024-01-01 03:21:53,218 - INFO - Epoch [6/30] (9198)  train_loss: 4.9935, val_loss: 4.8276, lr: 0.000174, 400.01s
2024-01-01 03:21:53,588 - INFO - Saved model at 6
2024-01-01 03:21:53,588 - INFO - Val loss decrease from 5.1145 to 4.8276, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch6.tar
2024-01-01 03:21:53,858 - INFO - {'mode': 'Train', 'epoch': 7, 'iter': 0, 'lr': 0.00017431448254773944, 'Loc acc(%)': 0.9345794392523363, 'MLM loss': 8.078521728515625, 'Contrastive loss': 0.002467778977006674, 'align_loss': 19.498374938964844, 'uniform_loss': -inf}
2024-01-01 03:24:10,775 - INFO - {'mode': 'Train', 'epoch': 7, 'iter': 500, 'lr': 0.00017431448254773944, 'Loc acc(%)': 0.9757673667205169, 'MLM loss': 8.0844087600708, 'Contrastive loss': 0.00026961215189658105, 'align_loss': 22.289024353027344, 'uniform_loss': -inf}
2024-01-01 03:26:27,451 - INFO - {'mode': 'Train', 'epoch': 7, 'iter': 1000, 'lr': 0.00017431448254773944, 'Loc acc(%)': 1.0716941516119154, 'MLM loss': 7.399692058563232, 'Contrastive loss': 0.0001955227489816025, 'align_loss': 22.221731185913086, 'uniform_loss': -inf}
2024-01-01 03:27:52,855 - INFO - Train: expid = 247850, Epoch = 7, avg_loss = 4.699178216845659, total_loc_acc = 1.1188039333734698%.
2024-01-01 03:27:52,865 - INFO - epoch complete!
2024-01-01 03:27:52,865 - INFO - evaluating now!
2024-01-01 03:27:52,955 - INFO - {'mode': 'Train', 'epoch': 7, 'iter': 0, 'lr': 0.00017431448254773944, 'Loc acc(%)': 3.4482758620689653, 'MLM loss': 6.351974010467529, 'Contrastive loss': 0.00042111295624636114, 'align_loss': 2.568320383034006e-07, 'uniform_loss': -inf}
2024-01-01 03:28:33,575 - INFO - Eval: expid = 247850, Epoch = 7, avg_loss = 4.487476162170166, total_loc_acc = 1.6680125164025437%.
2024-01-01 03:28:33,575 - INFO - Epoch [7/30] (10512)  train_loss: 4.6992, val_loss: 4.4875, lr: 0.000167, 399.99s
2024-01-01 03:28:33,935 - INFO - Saved model at 7
2024-01-01 03:28:33,935 - INFO - Val loss decrease from 4.8276 to 4.4875, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch7.tar
2024-01-01 03:28:34,205 - INFO - {'mode': 'Train', 'epoch': 8, 'iter': 0, 'lr': 0.00016691306063588583, 'Loc acc(%)': 0.0, 'MLM loss': 7.758331298828125, 'Contrastive loss': 0.0018067394848912954, 'align_loss': 20.131511688232422, 'uniform_loss': -inf}
2024-01-01 03:30:50,959 - INFO - {'mode': 'Train', 'epoch': 8, 'iter': 500, 'lr': 0.00016691306063588583, 'Loc acc(%)': 1.5686868468312527, 'MLM loss': 7.269064426422119, 'Contrastive loss': 0.0006906676571816206, 'align_loss': 26.40934181213379, 'uniform_loss': -inf}
2024-01-01 03:33:07,494 - INFO - {'mode': 'Train', 'epoch': 8, 'iter': 1000, 'lr': 0.00016691306063588583, 'Loc acc(%)': 1.6439137878056276, 'MLM loss': 7.061352729797363, 'Contrastive loss': 0.01681944727897644, 'align_loss': 30.491470336914062, 'uniform_loss': -inf}
2024-01-01 03:34:33,003 - INFO - Train: expid = 247850, Epoch = 8, avg_loss = 4.394305381600716, total_loc_acc = 1.772874517649225%.
2024-01-01 03:34:33,003 - INFO - epoch complete!
2024-01-01 03:34:33,003 - INFO - evaluating now!
2024-01-01 03:34:33,103 - INFO - {'mode': 'Train', 'epoch': 8, 'iter': 0, 'lr': 0.00016691306063588583, 'Loc acc(%)': 2.247191011235955, 'MLM loss': 6.769988536834717, 'Contrastive loss': 0.0002423080732114613, 'align_loss': 3.9268172713491367e-07, 'uniform_loss': -inf}
2024-01-01 03:35:13,710 - INFO - Eval: expid = 247850, Epoch = 8, avg_loss = 4.172690899949096, total_loc_acc = 2.5089697590978988%.
2024-01-01 03:35:13,710 - INFO - Epoch [8/30] (11826)  train_loss: 4.3943, val_loss: 4.1727, lr: 0.000159, 399.77s
2024-01-01 03:35:14,080 - INFO - Saved model at 8
2024-01-01 03:35:14,080 - INFO - Val loss decrease from 4.4875 to 4.1727, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch8.tar
2024-01-01 03:35:14,360 - INFO - {'mode': 'Train', 'epoch': 9, 'iter': 0, 'lr': 0.00015877852522924732, 'Loc acc(%)': 6.481481481481481, 'MLM loss': 6.422869682312012, 'Contrastive loss': 0.0020648736972361803, 'align_loss': 27.05109405517578, 'uniform_loss': -inf}
2024-01-01 03:37:31,147 - INFO - {'mode': 'Train', 'epoch': 9, 'iter': 500, 'lr': 0.00015877852522924732, 'Loc acc(%)': 2.3245263453520275, 'MLM loss': 6.676939487457275, 'Contrastive loss': 0.007640326861292124, 'align_loss': 26.256200790405273, 'uniform_loss': -inf}
2024-01-01 03:39:47,825 - INFO - {'mode': 'Train', 'epoch': 9, 'iter': 1000, 'lr': 0.00015877852522924732, 'Loc acc(%)': 2.4431477340895458, 'MLM loss': 7.141158103942871, 'Contrastive loss': 0.005066768731921911, 'align_loss': 36.11802291870117, 'uniform_loss': -inf}
2024-01-01 03:41:13,392 - INFO - Train: expid = 247850, Epoch = 9, avg_loss = 4.090508891930138, total_loc_acc = 2.5463753508866915%.
2024-01-01 03:41:13,392 - INFO - epoch complete!
2024-01-01 03:41:13,392 - INFO - evaluating now!
2024-01-01 03:41:13,482 - INFO - {'mode': 'Train', 'epoch': 9, 'iter': 0, 'lr': 0.00015877852522924732, 'Loc acc(%)': 4.0, 'MLM loss': 5.961041450500488, 'Contrastive loss': 6.25423199380748e-05, 'align_loss': 4.0769478459878883e-07, 'uniform_loss': -inf}
2024-01-01 03:41:54,122 - INFO - Eval: expid = 247850, Epoch = 9, avg_loss = 3.8365255937184375, total_loc_acc = 3.673798950343157%.
2024-01-01 03:41:54,122 - INFO - Epoch [9/30] (13140)  train_loss: 4.0905, val_loss: 3.8365, lr: 0.000150, 400.04s
2024-01-01 03:41:54,482 - INFO - Saved model at 9
2024-01-01 03:41:54,482 - INFO - Val loss decrease from 4.1727 to 3.8365, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch9.tar
2024-01-01 03:41:54,752 - INFO - {'mode': 'Train', 'epoch': 10, 'iter': 0, 'lr': 0.00015000000000000001, 'Loc acc(%)': 1.694915254237288, 'MLM loss': 6.258049964904785, 'Contrastive loss': 0.001569834421388805, 'align_loss': 38.63645935058594, 'uniform_loss': -inf}
2024-01-01 03:44:11,478 - INFO - {'mode': 'Train', 'epoch': 10, 'iter': 500, 'lr': 0.00015000000000000001, 'Loc acc(%)': 3.178686666085288, 'MLM loss': 6.059147357940674, 'Contrastive loss': 0.028248149901628494, 'align_loss': 31.234634399414062, 'uniform_loss': -inf}
2024-01-01 03:46:28,265 - INFO - {'mode': 'Train', 'epoch': 10, 'iter': 1000, 'lr': 0.00015000000000000001, 'Loc acc(%)': 3.2822541861583523, 'MLM loss': 6.39571475982666, 'Contrastive loss': 0.051981959491968155, 'align_loss': 51.99229431152344, 'uniform_loss': -inf}
2024-01-01 03:47:53,781 - INFO - Train: expid = 247850, Epoch = 10, avg_loss = 3.818906307764794, total_loc_acc = 3.3983705870064758%.
2024-01-01 03:47:53,781 - INFO - epoch complete!
2024-01-01 03:47:53,781 - INFO - evaluating now!
2024-01-01 03:47:53,871 - INFO - {'mode': 'Train', 'epoch': 10, 'iter': 0, 'lr': 0.00015000000000000001, 'Loc acc(%)': 0.0, 'MLM loss': 6.803679943084717, 'Contrastive loss': 0.001442045671865344, 'align_loss': 2.623680757096736e-07, 'uniform_loss': -inf}
2024-01-01 03:48:34,501 - INFO - Eval: expid = 247850, Epoch = 10, avg_loss = 3.569944285366633, total_loc_acc = 4.508311483338849%.
2024-01-01 03:48:34,501 - INFO - Epoch [10/30] (14454)  train_loss: 3.8189, val_loss: 3.5699, lr: 0.000141, 400.02s
2024-01-01 03:48:34,851 - INFO - Saved model at 10
2024-01-01 03:48:34,851 - INFO - Val loss decrease from 3.8365 to 3.5699, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch10.tar
2024-01-01 03:48:35,121 - INFO - {'mode': 'Train', 'epoch': 11, 'iter': 0, 'lr': 0.00014067366430758004, 'Loc acc(%)': 3.225806451612903, 'MLM loss': 6.793452262878418, 'Contrastive loss': 0.00012920537847094238, 'align_loss': 37.72816467285156, 'uniform_loss': -inf}
2024-01-01 03:50:51,857 - INFO - {'mode': 'Train', 'epoch': 11, 'iter': 500, 'lr': 0.00014067366430758004, 'Loc acc(%)': 4.133798870640976, 'MLM loss': 6.323287010192871, 'Contrastive loss': 0.00025808499776758254, 'align_loss': 41.078269958496094, 'uniform_loss': -inf}
2024-01-01 03:53:08,541 - INFO - {'mode': 'Train', 'epoch': 11, 'iter': 1000, 'lr': 0.00014067366430758004, 'Loc acc(%)': 4.3003256832267684, 'MLM loss': 5.556966781616211, 'Contrastive loss': 0.0068725948221981525, 'align_loss': 37.13396453857422, 'uniform_loss': -inf}
2024-01-01 03:54:34,171 - INFO - Train: expid = 247850, Epoch = 11, avg_loss = 3.560673971335819, total_loc_acc = 4.278651009738253%.
2024-01-01 03:54:34,181 - INFO - epoch complete!
2024-01-01 03:54:34,181 - INFO - evaluating now!
2024-01-01 03:54:34,271 - INFO - {'mode': 'Train', 'epoch': 11, 'iter': 0, 'lr': 0.00014067366430758004, 'Loc acc(%)': 6.25, 'MLM loss': 6.695642948150635, 'Contrastive loss': 8.880970199243166e-06, 'align_loss': 7.402896926578251e-07, 'uniform_loss': -inf}
2024-01-01 03:55:14,997 - INFO - Eval: expid = 247850, Epoch = 11, avg_loss = 3.333252915508671, total_loc_acc = 5.506060682109068%.
2024-01-01 03:55:15,007 - INFO - Epoch [11/30] (15768)  train_loss: 3.5607, val_loss: 3.3333, lr: 0.000131, 400.16s
2024-01-01 03:55:15,367 - INFO - Saved model at 11
2024-01-01 03:55:15,367 - INFO - Val loss decrease from 3.5699 to 3.3333, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch11.tar
2024-01-01 03:55:15,637 - INFO - {'mode': 'Train', 'epoch': 12, 'iter': 0, 'lr': 0.00013090169943749476, 'Loc acc(%)': 0.9803921568627451, 'MLM loss': 5.718513011932373, 'Contrastive loss': 0.001385193201713264, 'align_loss': 49.262123107910156, 'uniform_loss': -inf}
2024-01-01 03:57:32,411 - INFO - {'mode': 'Train', 'epoch': 12, 'iter': 500, 'lr': 0.00013090169943749476, 'Loc acc(%)': 4.925212973304426, 'MLM loss': 6.364370346069336, 'Contrastive loss': 0.020905297249555588, 'align_loss': 42.70413589477539, 'uniform_loss': -inf}
2024-01-01 03:59:49,144 - INFO - {'mode': 'Train', 'epoch': 12, 'iter': 1000, 'lr': 0.00013090169943749476, 'Loc acc(%)': 5.101758807857704, 'MLM loss': 4.731780529022217, 'Contrastive loss': 0.00022084824740886688, 'align_loss': 45.26764678955078, 'uniform_loss': -inf}
2024-01-01 04:01:14,779 - INFO - Train: expid = 247850, Epoch = 12, avg_loss = 3.3645688275405443, total_loc_acc = 5.239076496067959%.
2024-01-01 04:01:14,779 - INFO - epoch complete!
2024-01-01 04:01:14,779 - INFO - evaluating now!
2024-01-01 04:01:14,869 - INFO - {'mode': 'Train', 'epoch': 12, 'iter': 0, 'lr': 0.00013090169943749476, 'Loc acc(%)': 8.695652173913043, 'MLM loss': 5.055999279022217, 'Contrastive loss': 5.662438979925355e-07, 'align_loss': 5.264677156446851e-07, 'uniform_loss': -inf}
2024-01-01 04:01:55,459 - INFO - Eval: expid = 247850, Epoch = 12, avg_loss = 3.1299703017761717, total_loc_acc = 6.743814844373504%.
2024-01-01 04:01:55,459 - INFO - Epoch [12/30] (17082)  train_loss: 3.3646, val_loss: 3.1300, lr: 0.000121, 400.09s
2024-01-01 04:01:55,819 - INFO - Saved model at 12
2024-01-01 04:01:55,819 - INFO - Val loss decrease from 3.3333 to 3.1300, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch12.tar
2024-01-01 04:01:56,089 - INFO - {'mode': 'Train', 'epoch': 13, 'iter': 0, 'lr': 0.00012079116908177593, 'Loc acc(%)': 13.131313131313133, 'MLM loss': 4.91274881362915, 'Contrastive loss': 0.0002504015574231744, 'align_loss': 47.881248474121094, 'uniform_loss': -inf}
2024-01-01 04:04:12,922 - INFO - {'mode': 'Train', 'epoch': 13, 'iter': 500, 'lr': 0.00012079116908177593, 'Loc acc(%)': 6.0132948482463044, 'MLM loss': 5.569942951202393, 'Contrastive loss': 0.0008249668753705919, 'align_loss': 46.16217803955078, 'uniform_loss': -inf}
2024-01-01 04:06:29,799 - INFO - {'mode': 'Train', 'epoch': 13, 'iter': 1000, 'lr': 0.00012079116908177593, 'Loc acc(%)': 6.091464948645308, 'MLM loss': 5.054937362670898, 'Contrastive loss': 0.008053265511989594, 'align_loss': 50.25605010986328, 'uniform_loss': -inf}
2024-01-01 04:07:55,310 - INFO - Train: expid = 247850, Epoch = 13, avg_loss = 3.1847982366698337, total_loc_acc = 6.139083521934842%.
2024-01-01 04:07:55,310 - INFO - epoch complete!
2024-01-01 04:07:55,310 - INFO - evaluating now!
2024-01-01 04:07:55,410 - INFO - {'mode': 'Train', 'epoch': 13, 'iter': 0, 'lr': 0.00012079116908177593, 'Loc acc(%)': 5.555555555555555, 'MLM loss': 4.312900066375732, 'Contrastive loss': 7.823060514056124e-06, 'align_loss': 1.1888258768522064e-06, 'uniform_loss': -inf}
2024-01-01 04:08:36,030 - INFO - Eval: expid = 247850, Epoch = 13, avg_loss = 3.006618775189195, total_loc_acc = 7.459839357429719%.
2024-01-01 04:08:36,030 - INFO - Epoch [13/30] (18396)  train_loss: 3.1848, val_loss: 3.0066, lr: 0.000110, 400.21s
2024-01-01 04:08:36,380 - INFO - Saved model at 13
2024-01-01 04:08:36,380 - INFO - Val loss decrease from 3.1300 to 3.0066, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch13.tar
2024-01-01 04:08:36,650 - INFO - {'mode': 'Train', 'epoch': 14, 'iter': 0, 'lr': 0.00011045284632676536, 'Loc acc(%)': 6.666666666666667, 'MLM loss': 5.027968883514404, 'Contrastive loss': 0.06647602468729019, 'align_loss': 47.84739685058594, 'uniform_loss': -inf}
2024-01-01 04:10:53,578 - INFO - {'mode': 'Train', 'epoch': 14, 'iter': 500, 'lr': 0.00011045284632676536, 'Loc acc(%)': 6.416389811738648, 'MLM loss': 5.230450630187988, 'Contrastive loss': 0.006304687820374966, 'align_loss': 43.734214782714844, 'uniform_loss': -inf}
2024-01-01 04:13:10,318 - INFO - {'mode': 'Train', 'epoch': 14, 'iter': 1000, 'lr': 0.00011045284632676536, 'Loc acc(%)': 6.637119599798144, 'MLM loss': 5.664896011352539, 'Contrastive loss': 7.006699888734147e-05, 'align_loss': 46.04618835449219, 'uniform_loss': -inf}
2024-01-01 04:14:36,018 - INFO - Train: expid = 247850, Epoch = 14, avg_loss = 3.0465603255790117, total_loc_acc = 6.74443886937615%.
2024-01-01 04:14:36,018 - INFO - epoch complete!
2024-01-01 04:14:36,018 - INFO - evaluating now!
2024-01-01 04:14:36,118 - INFO - {'mode': 'Train', 'epoch': 14, 'iter': 0, 'lr': 0.00011045284632676536, 'Loc acc(%)': 9.63855421686747, 'MLM loss': 5.363066673278809, 'Contrastive loss': 0.004774623084813356, 'align_loss': 7.771391210553702e-07, 'uniform_loss': -inf}
2024-01-01 04:15:16,705 - INFO - Eval: expid = 247850, Epoch = 14, avg_loss = 2.8621956518251603, total_loc_acc = 8.619461824100922%.
2024-01-01 04:15:16,705 - INFO - Epoch [14/30] (19710)  train_loss: 3.0466, val_loss: 2.8622, lr: 0.000100, 400.32s
2024-01-01 04:15:17,055 - INFO - Saved model at 14
2024-01-01 04:15:17,055 - INFO - Val loss decrease from 3.0066 to 2.8622, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch14.tar
2024-01-01 04:15:17,325 - INFO - {'mode': 'Train', 'epoch': 15, 'iter': 0, 'lr': 0.00010000000000000003, 'Loc acc(%)': 5.839416058394161, 'MLM loss': 4.338404655456543, 'Contrastive loss': 7.678114343434572e-05, 'align_loss': 42.62422180175781, 'uniform_loss': -inf}
2024-01-01 04:17:34,021 - INFO - {'mode': 'Train', 'epoch': 15, 'iter': 500, 'lr': 0.00010000000000000003, 'Loc acc(%)': 7.576632607729898, 'MLM loss': 5.007899761199951, 'Contrastive loss': 0.03922264277935028, 'align_loss': 43.27165985107422, 'uniform_loss': -inf}
2024-01-01 04:19:50,774 - INFO - {'mode': 'Train', 'epoch': 15, 'iter': 1000, 'lr': 0.00010000000000000003, 'Loc acc(%)': 7.55818461777054, 'MLM loss': 5.149814605712891, 'Contrastive loss': 0.0038384071085602045, 'align_loss': 62.96562576293945, 'uniform_loss': -inf}
2024-01-01 04:21:16,397 - INFO - Train: expid = 247850, Epoch = 15, avg_loss = 2.92107909382569, total_loc_acc = 7.620335544943583%.
2024-01-01 04:21:16,397 - INFO - epoch complete!
2024-01-01 04:21:16,397 - INFO - evaluating now!
2024-01-01 04:21:16,497 - INFO - {'mode': 'Train', 'epoch': 15, 'iter': 0, 'lr': 0.00010000000000000003, 'Loc acc(%)': 9.322033898305085, 'MLM loss': 4.265085697174072, 'Contrastive loss': 3.904081495420542e-06, 'align_loss': 7.491282758564921e-07, 'uniform_loss': -inf}
2024-01-01 04:21:57,027 - INFO - Eval: expid = 247850, Epoch = 15, avg_loss = 2.74521661675684, total_loc_acc = 9.427815108939116%.
2024-01-01 04:21:57,027 - INFO - Epoch [15/30] (21024)  train_loss: 2.9211, val_loss: 2.7452, lr: 0.000090, 399.97s
2024-01-01 04:21:57,377 - INFO - Saved model at 15
2024-01-01 04:21:57,377 - INFO - Val loss decrease from 2.8622 to 2.7452, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch15.tar
2024-01-01 04:21:57,647 - INFO - {'mode': 'Train', 'epoch': 16, 'iter': 0, 'lr': 8.954715367323468e-05, 'Loc acc(%)': 9.473684210526317, 'MLM loss': 5.039498329162598, 'Contrastive loss': 0.010049218311905861, 'align_loss': 39.926841735839844, 'uniform_loss': -inf}
2024-01-01 04:24:14,479 - INFO - {'mode': 'Train', 'epoch': 16, 'iter': 500, 'lr': 8.954715367323468e-05, 'Loc acc(%)': 7.980645161290322, 'MLM loss': 4.741850852966309, 'Contrastive loss': 0.003032323904335499, 'align_loss': 53.46044158935547, 'uniform_loss': -inf}
2024-01-01 04:26:31,214 - INFO - {'mode': 'Train', 'epoch': 16, 'iter': 1000, 'lr': 8.954715367323468e-05, 'Loc acc(%)': 8.232855452937283, 'MLM loss': 3.7718207836151123, 'Contrastive loss': 0.004334532655775547, 'align_loss': 53.29655075073242, 'uniform_loss': -inf}
2024-01-01 04:27:56,860 - INFO - Train: expid = 247850, Epoch = 16, avg_loss = 2.8187522025413165, total_loc_acc = 8.302341026066744%.
2024-01-01 04:27:56,860 - INFO - epoch complete!
2024-01-01 04:27:56,860 - INFO - evaluating now!
2024-01-01 04:27:56,950 - INFO - {'mode': 'Train', 'epoch': 16, 'iter': 0, 'lr': 8.954715367323468e-05, 'Loc acc(%)': 13.131313131313133, 'MLM loss': 4.084016799926758, 'Contrastive loss': 5.260079888103064e-06, 'align_loss': 7.900437140051508e-07, 'uniform_loss': -inf}
2024-01-01 04:28:37,480 - INFO - Eval: expid = 247850, Epoch = 16, avg_loss = 2.6502550573653827, total_loc_acc = 10.537820252135015%.
2024-01-01 04:28:37,480 - INFO - Epoch [16/30] (22338)  train_loss: 2.8188, val_loss: 2.6503, lr: 0.000079, 400.10s
2024-01-01 04:28:37,810 - INFO - Saved model at 16
2024-01-01 04:28:37,810 - INFO - Val loss decrease from 2.7452 to 2.6503, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch16.tar
2024-01-01 04:28:38,080 - INFO - {'mode': 'Train', 'epoch': 17, 'iter': 0, 'lr': 7.920883091822407e-05, 'Loc acc(%)': 9.25925925925926, 'MLM loss': 4.574426651000977, 'Contrastive loss': 0.0008486432489007711, 'align_loss': 43.23271942138672, 'uniform_loss': -inf}
2024-01-01 04:30:54,747 - INFO - {'mode': 'Train', 'epoch': 17, 'iter': 500, 'lr': 7.920883091822407e-05, 'Loc acc(%)': 8.614167065269383, 'MLM loss': 4.442860126495361, 'Contrastive loss': 0.00013745168689638376, 'align_loss': 47.61601257324219, 'uniform_loss': -inf}
2024-01-01 04:33:11,420 - INFO - {'mode': 'Train', 'epoch': 17, 'iter': 1000, 'lr': 7.920883091822407e-05, 'Loc acc(%)': 8.755312689738918, 'MLM loss': 5.295870304107666, 'Contrastive loss': 0.0003700058732647449, 'align_loss': 41.64630126953125, 'uniform_loss': -inf}
2024-01-01 04:34:38,815 - INFO - Train: expid = 247850, Epoch = 17, avg_loss = 2.7351840396994325, total_loc_acc = 8.790008068854222%.
2024-01-01 04:34:38,825 - INFO - epoch complete!
2024-01-01 04:34:38,825 - INFO - evaluating now!
2024-01-01 04:34:38,915 - INFO - {'mode': 'Train', 'epoch': 17, 'iter': 0, 'lr': 7.920883091822407e-05, 'Loc acc(%)': 12.857142857142856, 'MLM loss': 4.109554290771484, 'Contrastive loss': 2.6672951207729056e-06, 'align_loss': 8.55393636811641e-07, 'uniform_loss': -inf}
2024-01-01 04:35:19,511 - INFO - Eval: expid = 247850, Epoch = 17, avg_loss = 2.5875310661041575, total_loc_acc = 11.18562571175503%.
2024-01-01 04:35:19,511 - INFO - Epoch [17/30] (23652)  train_loss: 2.7352, val_loss: 2.5875, lr: 0.000069, 401.70s
2024-01-01 04:35:19,861 - INFO - Saved model at 17
2024-01-01 04:35:19,861 - INFO - Val loss decrease from 2.6503 to 2.5875, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch17.tar
2024-01-01 04:35:20,131 - INFO - {'mode': 'Train', 'epoch': 18, 'iter': 0, 'lr': 6.909830056250527e-05, 'Loc acc(%)': 4.545454545454546, 'MLM loss': 4.696016311645508, 'Contrastive loss': 0.00037933685234747827, 'align_loss': 55.87482833862305, 'uniform_loss': -inf}
2024-01-01 04:37:36,931 - INFO - {'mode': 'Train', 'epoch': 18, 'iter': 500, 'lr': 6.909830056250527e-05, 'Loc acc(%)': 9.146637265711135, 'MLM loss': 4.363053321838379, 'Contrastive loss': 6.130395195214078e-05, 'align_loss': 43.45622253417969, 'uniform_loss': -inf}
2024-01-01 04:39:53,659 - INFO - {'mode': 'Train', 'epoch': 18, 'iter': 1000, 'lr': 6.909830056250527e-05, 'Loc acc(%)': 9.456358225999494, 'MLM loss': 5.456090450286865, 'Contrastive loss': 0.00021873624064028263, 'align_loss': 64.57730102539062, 'uniform_loss': -inf}
2024-01-01 04:41:19,185 - INFO - Train: expid = 247850, Epoch = 18, avg_loss = 2.6520198090980043, total_loc_acc = 9.481797146804722%.
2024-01-01 04:41:19,185 - INFO - epoch complete!
2024-01-01 04:41:19,185 - INFO - evaluating now!
2024-01-01 04:41:19,285 - INFO - {'mode': 'Train', 'epoch': 18, 'iter': 0, 'lr': 6.909830056250527e-05, 'Loc acc(%)': 4.477611940298507, 'MLM loss': 4.1639180183410645, 'Contrastive loss': 4.902454747934826e-06, 'align_loss': 3.5131515119246615e-07, 'uniform_loss': -inf}
2024-01-01 04:41:59,775 - INFO - Eval: expid = 247850, Epoch = 18, avg_loss = 2.4903529147579246, total_loc_acc = 11.872354447063595%.
2024-01-01 04:41:59,775 - INFO - Epoch [18/30] (24966)  train_loss: 2.6520, val_loss: 2.4904, lr: 0.000059, 399.91s
2024-01-01 04:42:00,115 - INFO - Saved model at 18
2024-01-01 04:42:00,115 - INFO - Val loss decrease from 2.5875 to 2.4904, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch18.tar
2024-01-01 04:42:00,375 - INFO - {'mode': 'Train', 'epoch': 19, 'iter': 0, 'lr': 5.932633569241999e-05, 'Loc acc(%)': 5.9405940594059405, 'MLM loss': 4.307805061340332, 'Contrastive loss': 0.0007293202797882259, 'align_loss': 58.46175003051758, 'uniform_loss': -inf}
2024-01-01 04:44:16,995 - INFO - {'mode': 'Train', 'epoch': 19, 'iter': 500, 'lr': 5.932633569241999e-05, 'Loc acc(%)': 9.645664956286199, 'MLM loss': 3.5326340198516846, 'Contrastive loss': 0.0006795728113502264, 'align_loss': 54.60091018676758, 'uniform_loss': -inf}
2024-01-01 04:46:33,501 - INFO - {'mode': 'Train', 'epoch': 19, 'iter': 1000, 'lr': 5.932633569241999e-05, 'Loc acc(%)': 9.94126461548558, 'MLM loss': 3.900679349899292, 'Contrastive loss': 0.00013826708891429007, 'align_loss': 53.36254119873047, 'uniform_loss': -inf}
2024-01-01 04:47:59,018 - INFO - Train: expid = 247850, Epoch = 19, avg_loss = 2.5959905236279037, total_loc_acc = 10.038410153640614%.
2024-01-01 04:47:59,018 - INFO - epoch complete!
2024-01-01 04:47:59,018 - INFO - evaluating now!
2024-01-01 04:47:59,118 - INFO - {'mode': 'Train', 'epoch': 19, 'iter': 0, 'lr': 5.932633569241999e-05, 'Loc acc(%)': 11.76470588235294, 'MLM loss': 4.0264668464660645, 'Contrastive loss': 1.9222475202695932e-06, 'align_loss': 1.0761054909380618e-06, 'uniform_loss': -inf}
2024-01-01 04:48:39,578 - INFO - Eval: expid = 247850, Epoch = 19, avg_loss = 2.4545230364690633, total_loc_acc = 12.860020140986908%.
2024-01-01 04:48:39,578 - INFO - Epoch [19/30] (26280)  train_loss: 2.5960, val_loss: 2.4545, lr: 0.000050, 399.46s
2024-01-01 04:48:39,928 - INFO - Saved model at 19
2024-01-01 04:48:39,928 - INFO - Val loss decrease from 2.4904 to 2.4545, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch19.tar
2024-01-01 04:48:40,198 - INFO - {'mode': 'Train', 'epoch': 20, 'iter': 0, 'lr': 5.000000000000002e-05, 'Loc acc(%)': 9.574468085106384, 'MLM loss': 3.363582134246826, 'Contrastive loss': 0.1111166700720787, 'align_loss': 45.62424087524414, 'uniform_loss': -inf}
2024-01-01 04:50:56,817 - INFO - {'mode': 'Train', 'epoch': 20, 'iter': 500, 'lr': 5.000000000000002e-05, 'Loc acc(%)': 10.845790889447459, 'MLM loss': 4.041595935821533, 'Contrastive loss': 0.005806677974760532, 'align_loss': 57.93836212158203, 'uniform_loss': -inf}
2024-01-01 04:53:13,372 - INFO - {'mode': 'Train', 'epoch': 20, 'iter': 1000, 'lr': 5.000000000000002e-05, 'Loc acc(%)': 10.728549484309854, 'MLM loss': 4.63610315322876, 'Contrastive loss': 0.00021103663311805576, 'align_loss': 64.34481048583984, 'uniform_loss': -inf}
2024-01-01 04:54:38,907 - INFO - Train: expid = 247850, Epoch = 20, avg_loss = 2.542692336771223, total_loc_acc = 10.803769633507853%.
2024-01-01 04:54:38,907 - INFO - epoch complete!
2024-01-01 04:54:38,907 - INFO - evaluating now!
2024-01-01 04:54:39,007 - INFO - {'mode': 'Train', 'epoch': 20, 'iter': 0, 'lr': 5.000000000000002e-05, 'Loc acc(%)': 8.98876404494382, 'MLM loss': 4.429938793182373, 'Contrastive loss': 2.148655585187953e-05, 'align_loss': 1.1535780686244834e-06, 'uniform_loss': -inf}
2024-01-01 04:55:19,773 - INFO - Eval: expid = 247850, Epoch = 20, avg_loss = 2.403186561310128, total_loc_acc = 13.347204953183283%.
2024-01-01 04:55:19,773 - INFO - Epoch [20/30] (27594)  train_loss: 2.5427, val_loss: 2.4032, lr: 0.000041, 399.85s
2024-01-01 04:55:20,143 - INFO - Saved model at 20
2024-01-01 04:55:20,143 - INFO - Val loss decrease from 2.4545 to 2.4032, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch20.tar
2024-01-01 04:55:20,413 - INFO - {'mode': 'Train', 'epoch': 21, 'iter': 0, 'lr': 4.12214747707527e-05, 'Loc acc(%)': 15.65217391304348, 'MLM loss': 3.57165265083313, 'Contrastive loss': 0.0006109669920988381, 'align_loss': 49.55491638183594, 'uniform_loss': -inf}
2024-01-01 04:57:37,173 - INFO - {'mode': 'Train', 'epoch': 21, 'iter': 500, 'lr': 4.12214747707527e-05, 'Loc acc(%)': 10.925057511944788, 'MLM loss': 3.4982173442840576, 'Contrastive loss': 0.0001707006013020873, 'align_loss': 45.09245681762695, 'uniform_loss': -inf}
2024-01-01 04:59:53,823 - INFO - {'mode': 'Train', 'epoch': 21, 'iter': 1000, 'lr': 4.12214747707527e-05, 'Loc acc(%)': 11.075492690879848, 'MLM loss': 4.017247676849365, 'Contrastive loss': 7.786247442709282e-05, 'align_loss': 60.35527038574219, 'uniform_loss': -inf}
2024-01-01 05:01:19,331 - INFO - Train: expid = 247850, Epoch = 21, avg_loss = 2.4899374994150216, total_loc_acc = 11.060428523602276%.
2024-01-01 05:01:19,341 - INFO - epoch complete!
2024-01-01 05:01:19,341 - INFO - evaluating now!
2024-01-01 05:01:19,431 - INFO - {'mode': 'Train', 'epoch': 21, 'iter': 0, 'lr': 4.12214747707527e-05, 'Loc acc(%)': 16.867469879518072, 'MLM loss': 4.071139335632324, 'Contrastive loss': 8.791676009423099e-07, 'align_loss': 9.788045645109378e-07, 'uniform_loss': -inf}
2024-01-01 05:01:59,930 - INFO - Eval: expid = 247850, Epoch = 21, avg_loss = 2.355044585384735, total_loc_acc = 14.0830748894199%.
2024-01-01 05:01:59,930 - INFO - Epoch [21/30] (28908)  train_loss: 2.4899, val_loss: 2.3550, lr: 0.000033, 399.79s
2024-01-01 05:02:00,280 - INFO - Saved model at 21
2024-01-01 05:02:00,280 - INFO - Val loss decrease from 2.4032 to 2.3550, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch21.tar
2024-01-01 05:02:00,550 - INFO - {'mode': 'Train', 'epoch': 22, 'iter': 0, 'lr': 3.308693936411421e-05, 'Loc acc(%)': 14.666666666666666, 'MLM loss': 4.419896125793457, 'Contrastive loss': 0.00033312500454485416, 'align_loss': 57.32677459716797, 'uniform_loss': -inf}
2024-01-01 05:04:17,227 - INFO - {'mode': 'Train', 'epoch': 22, 'iter': 500, 'lr': 3.308693936411421e-05, 'Loc acc(%)': 11.313224853375667, 'MLM loss': 4.198571681976318, 'Contrastive loss': 0.0029831016436219215, 'align_loss': 48.55025863647461, 'uniform_loss': -inf}
2024-01-01 05:06:33,798 - INFO - {'mode': 'Train', 'epoch': 22, 'iter': 1000, 'lr': 3.308693936411421e-05, 'Loc acc(%)': 11.479036021987016, 'MLM loss': 4.145127296447754, 'Contrastive loss': 9.924086043611169e-06, 'align_loss': 45.37022399902344, 'uniform_loss': -inf}
2024-01-01 05:07:59,305 - INFO - Train: expid = 247850, Epoch = 22, avg_loss = 2.45893774538824, total_loc_acc = 11.481525143992725%.
2024-01-01 05:07:59,305 - INFO - epoch complete!
2024-01-01 05:07:59,305 - INFO - evaluating now!
2024-01-01 05:07:59,405 - INFO - {'mode': 'Train', 'epoch': 22, 'iter': 0, 'lr': 3.308693936411421e-05, 'Loc acc(%)': 21.11111111111111, 'MLM loss': 3.8387539386749268, 'Contrastive loss': 8.341289503732696e-05, 'align_loss': 9.696302640804788e-07, 'uniform_loss': -inf}
2024-01-01 05:08:39,915 - INFO - Eval: expid = 247850, Epoch = 22, avg_loss = 2.344528080121567, total_loc_acc = 14.341881642695888%.
2024-01-01 05:08:39,915 - INFO - Epoch [22/30] (30222)  train_loss: 2.4589, val_loss: 2.3445, lr: 0.000026, 399.64s
2024-01-01 05:08:40,265 - INFO - Saved model at 22
2024-01-01 05:08:40,265 - INFO - Val loss decrease from 2.3550 to 2.3445, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch22.tar
2024-01-01 05:08:40,535 - INFO - {'mode': 'Train', 'epoch': 23, 'iter': 0, 'lr': 2.5685517452260587e-05, 'Loc acc(%)': 9.090909090909092, 'MLM loss': 3.7575769424438477, 'Contrastive loss': 2.4235932869487442e-05, 'align_loss': 46.778236389160156, 'uniform_loss': -inf}
2024-01-01 05:10:57,352 - INFO - {'mode': 'Train', 'epoch': 23, 'iter': 500, 'lr': 2.5685517452260587e-05, 'Loc acc(%)': 12.061895375971362, 'MLM loss': 3.33215069770813, 'Contrastive loss': 0.002412335015833378, 'align_loss': 74.85183715820312, 'uniform_loss': -inf}
2024-01-01 05:13:13,985 - INFO - {'mode': 'Train', 'epoch': 23, 'iter': 1000, 'lr': 2.5685517452260587e-05, 'Loc acc(%)': 12.13281677403508, 'MLM loss': 4.225766181945801, 'Contrastive loss': 7.344230107264593e-05, 'align_loss': 45.91722869873047, 'uniform_loss': -inf}
2024-01-01 05:14:39,579 - INFO - Train: expid = 247850, Epoch = 23, avg_loss = 2.411241333143533, total_loc_acc = 12.127739277018168%.
2024-01-01 05:14:39,579 - INFO - epoch complete!
2024-01-01 05:14:39,579 - INFO - evaluating now!
2024-01-01 05:14:39,669 - INFO - {'mode': 'Train', 'epoch': 23, 'iter': 0, 'lr': 2.5685517452260587e-05, 'Loc acc(%)': 11.214953271028037, 'MLM loss': 4.399565696716309, 'Contrastive loss': 8.061401786108036e-06, 'align_loss': 1.0423757430544356e-06, 'uniform_loss': -inf}
2024-01-01 05:15:20,316 - INFO - Eval: expid = 247850, Epoch = 23, avg_loss = 2.320666541791942, total_loc_acc = 14.950826269587743%.
2024-01-01 05:15:20,326 - INFO - Epoch [23/30] (31536)  train_loss: 2.4112, val_loss: 2.3207, lr: 0.000019, 400.05s
2024-01-01 05:15:20,686 - INFO - Saved model at 23
2024-01-01 05:15:20,686 - INFO - Val loss decrease from 2.3445 to 2.3207, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch23.tar
2024-01-01 05:15:20,956 - INFO - {'mode': 'Train', 'epoch': 24, 'iter': 0, 'lr': 1.9098300562505266e-05, 'Loc acc(%)': 5.4945054945054945, 'MLM loss': 3.8678174018859863, 'Contrastive loss': 2.206820499850437e-05, 'align_loss': 56.80009460449219, 'uniform_loss': -inf}
2024-01-01 05:17:37,712 - INFO - {'mode': 'Train', 'epoch': 24, 'iter': 500, 'lr': 1.9098300562505266e-05, 'Loc acc(%)': 12.447637444924359, 'MLM loss': 4.523396015167236, 'Contrastive loss': 0.0028134575113654137, 'align_loss': 59.19122314453125, 'uniform_loss': -inf}
2024-01-01 05:19:54,385 - INFO - {'mode': 'Train', 'epoch': 24, 'iter': 1000, 'lr': 1.9098300562505266e-05, 'Loc acc(%)': 12.390154330433262, 'MLM loss': 4.321651458740234, 'Contrastive loss': 0.0014756672317162156, 'align_loss': 60.1247444152832, 'uniform_loss': -inf}
2024-01-01 05:21:19,892 - INFO - Train: expid = 247850, Epoch = 24, avg_loss = 2.3955022579277307, total_loc_acc = 12.36873787706508%.
2024-01-01 05:21:19,892 - INFO - epoch complete!
2024-01-01 05:21:19,892 - INFO - evaluating now!
2024-01-01 05:21:19,992 - INFO - {'mode': 'Train', 'epoch': 24, 'iter': 0, 'lr': 1.9098300562505266e-05, 'Loc acc(%)': 17.123287671232877, 'MLM loss': 3.245434522628784, 'Contrastive loss': 2.011650394706521e-06, 'align_loss': 9.708811603559298e-07, 'uniform_loss': -inf}
2024-01-01 05:22:00,602 - INFO - Eval: expid = 247850, Epoch = 24, avg_loss = 2.2920489765737697, total_loc_acc = 15.463054562057682%.
2024-01-01 05:22:00,602 - INFO - Epoch [24/30] (32850)  train_loss: 2.3955, val_loss: 2.2920, lr: 0.000013, 399.92s
2024-01-01 05:22:00,972 - INFO - Saved model at 24
2024-01-01 05:22:00,972 - INFO - Val loss decrease from 2.3207 to 2.2920, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch24.tar
2024-01-01 05:22:01,242 - INFO - {'mode': 'Train', 'epoch': 25, 'iter': 0, 'lr': 1.339745962155613e-05, 'Loc acc(%)': 14.285714285714285, 'MLM loss': 3.9293620586395264, 'Contrastive loss': 7.792709220666438e-05, 'align_loss': 41.7173957824707, 'uniform_loss': -inf}
2024-01-01 05:24:18,214 - INFO - {'mode': 'Train', 'epoch': 25, 'iter': 500, 'lr': 1.339745962155613e-05, 'Loc acc(%)': 12.462307133581318, 'MLM loss': 4.264898777008057, 'Contrastive loss': 9.557601879350841e-05, 'align_loss': 50.56846618652344, 'uniform_loss': -inf}
2024-01-01 05:26:34,771 - INFO - {'mode': 'Train', 'epoch': 25, 'iter': 1000, 'lr': 1.339745962155613e-05, 'Loc acc(%)': 12.457897681766816, 'MLM loss': 4.4223198890686035, 'Contrastive loss': 0.00011862331302836537, 'align_loss': 61.01333236694336, 'uniform_loss': -inf}
2024-01-01 05:28:00,218 - INFO - Train: expid = 247850, Epoch = 25, avg_loss = 2.384024413571873, total_loc_acc = 12.483903874776328%.
2024-01-01 05:28:00,218 - INFO - epoch complete!
2024-01-01 05:28:00,218 - INFO - evaluating now!
2024-01-01 05:28:00,308 - INFO - {'mode': 'Train', 'epoch': 25, 'iter': 0, 'lr': 1.339745962155613e-05, 'Loc acc(%)': 8.24742268041237, 'MLM loss': 4.275754928588867, 'Contrastive loss': 2.1308608211256796e-06, 'align_loss': 1.050334503815975e-06, 'uniform_loss': -inf}
2024-01-01 05:28:40,908 - INFO - Eval: expid = 247850, Epoch = 25, avg_loss = 2.27813744844367, total_loc_acc = 15.838667073046835%.
2024-01-01 05:28:40,918 - INFO - Epoch [25/30] (34164)  train_loss: 2.3840, val_loss: 2.2781, lr: 0.000009, 399.95s
2024-01-01 05:28:41,268 - INFO - Saved model at 25
2024-01-01 05:28:41,268 - INFO - Val loss decrease from 2.2920 to 2.2781, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch25.tar
2024-01-01 05:28:41,538 - INFO - {'mode': 'Train', 'epoch': 26, 'iter': 0, 'lr': 8.645454235739903e-06, 'Loc acc(%)': 13.20754716981132, 'MLM loss': 4.246498107910156, 'Contrastive loss': 0.0022908307146281004, 'align_loss': 56.16015625, 'uniform_loss': -inf}
2024-01-01 05:30:58,142 - INFO - {'mode': 'Train', 'epoch': 26, 'iter': 500, 'lr': 8.645454235739903e-06, 'Loc acc(%)': 12.686187282827612, 'MLM loss': 3.6987218856811523, 'Contrastive loss': 1.0304065654054284e-05, 'align_loss': 47.30424880981445, 'uniform_loss': -inf}
2024-01-01 05:33:14,665 - INFO - {'mode': 'Train', 'epoch': 26, 'iter': 1000, 'lr': 8.645454235739903e-06, 'Loc acc(%)': 12.56150570375764, 'MLM loss': 3.236072540283203, 'Contrastive loss': 0.01457969006150961, 'align_loss': 49.07726287841797, 'uniform_loss': -inf}
2024-01-01 05:34:40,192 - INFO - Train: expid = 247850, Epoch = 26, avg_loss = 2.3721874729139074, total_loc_acc = 12.556847740354762%.
2024-01-01 05:34:40,192 - INFO - epoch complete!
2024-01-01 05:34:40,192 - INFO - evaluating now!
2024-01-01 05:34:40,282 - INFO - {'mode': 'Train', 'epoch': 26, 'iter': 0, 'lr': 8.645454235739903e-06, 'Loc acc(%)': 15.53398058252427, 'MLM loss': 4.0614190101623535, 'Contrastive loss': 1.937150670983101e-07, 'align_loss': 1.1112909987787134e-06, 'uniform_loss': -inf}
2024-01-01 05:35:20,889 - INFO - Eval: expid = 247850, Epoch = 26, avg_loss = 2.2630564208444395, total_loc_acc = 15.843767425356111%.
2024-01-01 05:35:20,889 - INFO - Epoch [26/30] (35478)  train_loss: 2.3722, val_loss: 2.2631, lr: 0.000005, 399.62s
2024-01-01 05:35:21,249 - INFO - Saved model at 26
2024-01-01 05:35:21,259 - INFO - Val loss decrease from 2.2781 to 2.2631, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch26.tar
2024-01-01 05:35:21,529 - INFO - {'mode': 'Train', 'epoch': 27, 'iter': 0, 'lr': 4.8943483704846475e-06, 'Loc acc(%)': 17.391304347826086, 'MLM loss': 4.10133171081543, 'Contrastive loss': 6.649715942330658e-05, 'align_loss': 44.044944763183594, 'uniform_loss': -inf}
2024-01-01 05:37:38,185 - INFO - {'mode': 'Train', 'epoch': 27, 'iter': 500, 'lr': 4.8943483704846475e-06, 'Loc acc(%)': 12.855039833737445, 'MLM loss': 4.11672306060791, 'Contrastive loss': 0.023394810035824776, 'align_loss': 56.463340759277344, 'uniform_loss': -inf}
2024-01-01 05:39:54,892 - INFO - {'mode': 'Train', 'epoch': 27, 'iter': 1000, 'lr': 4.8943483704846475e-06, 'Loc acc(%)': 12.875362191588374, 'MLM loss': 3.840226888656616, 'Contrastive loss': 1.9296623577247374e-05, 'align_loss': 44.253387451171875, 'uniform_loss': -inf}
2024-01-01 05:41:20,488 - INFO - Train: expid = 247850, Epoch = 27, avg_loss = 2.340990988086892, total_loc_acc = 12.946185371740826%.
2024-01-01 05:41:20,488 - INFO - epoch complete!
2024-01-01 05:41:20,488 - INFO - evaluating now!
2024-01-01 05:41:20,588 - INFO - {'mode': 'Train', 'epoch': 27, 'iter': 0, 'lr': 4.8943483704846475e-06, 'Loc acc(%)': 23.404255319148938, 'MLM loss': 4.575387001037598, 'Contrastive loss': 1.937150670983101e-07, 'align_loss': 6.231098836906312e-07, 'uniform_loss': -inf}
2024-01-01 05:42:01,158 - INFO - Eval: expid = 247850, Epoch = 27, avg_loss = 2.248868339954446, total_loc_acc = 16.015506232897536%.
2024-01-01 05:42:01,158 - INFO - Epoch [27/30] (36792)  train_loss: 2.3410, val_loss: 2.2489, lr: 0.000002, 399.90s
2024-01-01 05:42:01,538 - INFO - Saved model at 27
2024-01-01 05:42:01,538 - INFO - Val loss decrease from 2.2631 to 2.2489, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch27.tar
2024-01-01 05:42:01,808 - INFO - {'mode': 'Train', 'epoch': 28, 'iter': 0, 'lr': 2.1852399266194314e-06, 'Loc acc(%)': 12.903225806451612, 'MLM loss': 4.709441184997559, 'Contrastive loss': 0.00012328381126280874, 'align_loss': 55.37953567504883, 'uniform_loss': -inf}
2024-01-01 05:44:18,564 - INFO - {'mode': 'Train', 'epoch': 28, 'iter': 500, 'lr': 2.1852399266194314e-06, 'Loc acc(%)': 12.743907726996792, 'MLM loss': 4.636585712432861, 'Contrastive loss': 3.3109212381532416e-05, 'align_loss': 51.83576202392578, 'uniform_loss': -inf}
2024-01-01 05:46:35,260 - INFO - {'mode': 'Train', 'epoch': 28, 'iter': 1000, 'lr': 2.1852399266194314e-06, 'Loc acc(%)': 12.882801679600764, 'MLM loss': 4.388739585876465, 'Contrastive loss': 3.249065048294142e-05, 'align_loss': 56.481082916259766, 'uniform_loss': -inf}
2024-01-01 05:48:00,763 - INFO - Train: expid = 247850, Epoch = 28, avg_loss = 2.3531435481308076, total_loc_acc = 12.87890857559724%.
2024-01-01 05:48:00,773 - INFO - epoch complete!
2024-01-01 05:48:00,773 - INFO - evaluating now!
2024-01-01 05:48:00,863 - INFO - {'mode': 'Train', 'epoch': 28, 'iter': 0, 'lr': 2.1852399266194314e-06, 'Loc acc(%)': 20.0, 'MLM loss': 3.9080207347869873, 'Contrastive loss': 1.4305087461252697e-06, 'align_loss': 6.123027560533956e-07, 'uniform_loss': -inf}
2024-01-01 05:48:41,443 - INFO - Eval: expid = 247850, Epoch = 28, avg_loss = 2.2453423708541207, total_loc_acc = 16.462677546086432%.
2024-01-01 05:48:41,443 - INFO - Epoch [28/30] (38106)  train_loss: 2.3531, val_loss: 2.2453, lr: 0.000001, 399.90s
2024-01-01 05:48:41,803 - INFO - Saved model at 28
2024-01-01 05:48:41,803 - INFO - Val loss decrease from 2.2489 to 2.2453, saving to ./libcity/cache/247850/model_cache/BERTContrastiveLM_bj_epoch28.tar
2024-01-01 05:48:42,073 - INFO - {'mode': 'Train', 'epoch': 29, 'iter': 0, 'lr': 5.4781046317266e-07, 'Loc acc(%)': 15.59633027522936, 'MLM loss': 3.8601818084716797, 'Contrastive loss': 0.0001218654724652879, 'align_loss': 49.04960632324219, 'uniform_loss': -inf}
2024-01-01 05:50:58,895 - INFO - {'mode': 'Train', 'epoch': 29, 'iter': 500, 'lr': 5.4781046317266e-07, 'Loc acc(%)': 12.969957835558679, 'MLM loss': 4.5953850746154785, 'Contrastive loss': 0.00015895951946731657, 'align_loss': 60.07178497314453, 'uniform_loss': -inf}
2024-01-01 05:53:15,568 - INFO - {'mode': 'Train', 'epoch': 29, 'iter': 1000, 'lr': 5.4781046317266e-07, 'Loc acc(%)': 12.950012664779798, 'MLM loss': 4.042376518249512, 'Contrastive loss': 0.0017020071391016245, 'align_loss': 55.892066955566406, 'uniform_loss': -inf}
2024-01-01 05:54:41,028 - INFO - Train: expid = 247850, Epoch = 29, avg_loss = 2.3501893064202783, total_loc_acc = 12.964717919472657%.
2024-01-01 05:54:41,028 - INFO - epoch complete!
2024-01-01 05:54:41,038 - INFO - evaluating now!
2024-01-01 05:54:41,128 - INFO - {'mode': 'Train', 'epoch': 29, 'iter': 0, 'lr': 5.4781046317266e-07, 'Loc acc(%)': 20.833333333333336, 'MLM loss': 3.7793664932250977, 'Contrastive loss': 4.380916834634263e-06, 'align_loss': 6.552268132509198e-07, 'uniform_loss': -inf}
2024-01-01 05:55:21,800 - INFO - Eval: expid = 247850, Epoch = 29, avg_loss = 2.2507412964350557, total_loc_acc = 15.953694042828042%.
2024-01-01 05:55:21,800 - INFO - Epoch [29/30] (39420)  train_loss: 2.3502, val_loss: 2.2507, lr: 0.000020, 400.00s
2024-01-01 05:55:21,800 - INFO - Trained totally 30 epochs, average train time is 359.175s, average eval time is 40.701s
2024-01-01 05:55:21,960 - INFO - Loaded model at 28
2024-01-01 05:55:22,050 - INFO - Save png at ./libcity/cache/247850/247850_loss.png
2024-01-01 05:55:22,120 - INFO - Save png at ./libcity/cache/247850/247850_acc.png
2024-01-01 05:55:22,180 - INFO - Save png at ./libcity/cache/247850/247850_lr.png
2024-01-01 05:55:22,500 - INFO - Saved model at ./libcity/cache/247850/model_cache/247850_BERTContrastiveLM_bj.pt
2024-01-01 05:55:22,500 - INFO - Start evaluating ...
2024-01-01 05:55:22,600 - INFO - {'mode': 'Train', 'epoch': 0, 'iter': 0, 'lr': 5.4781046317266e-07, 'Loc acc(%)': 22.07792207792208, 'MLM loss': 3.745893955230713, 'Contrastive loss': 4.5623324695043266e-05, 'align_loss': 1.0488004136277596e-06, 'uniform_loss': -inf}
2024-01-01 05:56:07,267 - INFO - Test: expid = 247850, Epoch = 0, avg_loss = 2.2152698548961447, total_loc_acc = 16.45588127787119%.
2024-01-01 05:56:07,277 - INFO - Evaluate result is {
 "Precision@1": 0.1645588127787119,
 "Recall@1": 0.1645588127787119,
 "F1@1": 0.1645588127787119,
 "MRR@1": 0.1645588127787119,
 "MAP@1": 0.1645588127787119,
 "NDCG@1": 0.1645588127787119,
 "Precision@5": 0.10164485708019592,
 "Recall@5": 0.5082242854009796,
 "F1@5": 0.16940809513365987,
 "MRR@5": 0.286777379762978,
 "MAP@5": 0.286777379762978,
 "NDCG@5": 0.3416777490842092,
 "Precision@10": 0.06672515047396252,
 "Recall@10": 0.6672515047396252,
 "F1@10": 0.12131845540720457,
 "MRR@10": 0.3082269156251173,
 "MAP@10": 0.3082269156251173,
 "NDCG@10": 0.3933311582016692
}
2024-01-01 05:56:07,277 - INFO - Evaluate result is saved at ./libcity/cache/247850/evaluate_cache\247850_2024_01_01_05_56_07_BERTContrastiveLM_bj.json
2024-01-01 05:56:07,277 - INFO - Evaluate result is saved at ./libcity/cache/247850/evaluate_cache\247850_2024_01_01_05_56_07_BERTContrastiveLM_bj.csv
2024-01-01 05:56:07,287 - INFO - 
    Precision    Recall        F1       MRR      NDCG
1    0.164559  0.164559  0.164559  0.164559  0.164559
5    0.101645  0.508224  0.169408  0.286777  0.341678
10   0.066725  0.667252  0.121318  0.308227  0.393331
2024-01-01 05:56:07,287 - INFO - Test time 44.78668546676636s.
